#!/home/el/venv/bin/python3.7

import json
import re
import sys
from typing import Dict, List

import requests
import wikitextparser

URL = "https://en.wikipedia.org/w/api.php"
TAG_RE = re.compile(r"<[^>]+>")
HTML_ESCAPE_TABLE = {
    "&amp;": "&",
    "&quot;": "'",
    "&apos;": "'",
    "&gt;": ">",
    "&lt;": "<",
    '"': "'",  # not an html escape but needed
}


def remove_tags(text: str) -> str:
    """
    Remove tags from a piece of html
    """
    for key, value in HTML_ESCAPE_TABLE.items():
        text = text.replace(key, value)

    return TAG_RE.sub("", text)


def format_results(results: List) -> list:
    """
    Format results
    """
    return [
        {
            "title": result["title"],
            "extract": remove_tags(result["extract"]),
            "page_id": result["pageid"],
            "url": result["fullurl"],
        }
        for result in results
    ]


def format_url(parameters: Dict) -> str:
    """
    Format a url for the wikipedia api
    """

    def _format_parameter(key: str, value: str) -> str:
        return f"{key}={value}" if value is not None else f"{key}"

    return f"{URL}?{'&'.join(_format_parameter(key, value) for key, value in parameters.items())}"


def search(query: str) -> str:
    """
    Search for wikipedia articles matching a given query term
    """
    defaults = {
        "action": "query",
        "format": "json",
        "prop": "extracts|info",
        "generator": "search",
        "inprop": "url",
        "exsentences": 1,
        "exlimit": "max",
        "exintro": None,
        "explaintext": None,
    }

    url = format_url({**defaults, **{"gsrsearch": query}})
    print(url)
    response = requests.get(url)

    if response.status_code != 200:
        raise KeyError(f"Bad search: {query}")

    hits = [*json.loads(response.text)["query"]["pages"].values()]

    return json.dumps(format_results(hits))


def scrape(title: str) -> str:
    """
    Search for wikipedia articles matching a given query term
    """

    defaults = {
        "action": "parse",
        "formatversion": 1,
        "prop": "wikitext",
        "format": "json",
    }

    url = format_url({**defaults, **{"page": title}})
    response = requests.get(url)

    if response.status_code != 200:
        raise KeyError(f"Bad search: {title}")

    text = json.loads(response.text)['parse']['wikitext']['*']
    return wikitextparser.remove_markup(text)


if __name__ == "__main__":

    action = sys.argv[1]
    query = sys.argv[2]
    lookup = {"search": search, "scrape": scrape}

    print(lookup[action](query))
